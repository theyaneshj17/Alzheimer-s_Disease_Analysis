{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83d4953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING BRAINNET VIEWER FILES FOR GOLD STANDARD CONNECTIONS\n",
      "==========================================================\n",
      "✅ Loading C:/Users/theya/Downloads/ADNIFinal/FMRIAnalysis/Comprehensive_Publication_Analysis_Corrected/Gold_Standard_Connections_Only_Corrected.csv...\n",
      "✅ Loaded 53 gold standard connections\n",
      "✅ Defined 68 reference node names\n",
      "\n",
      "📊 Processing S1_vs_S2...\n",
      "   Found 20 connections for S1_vs_S2\n",
      "   ✅ Successfully mapped 20 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 17 nodes involved in connections\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Early_vs_Advanced_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created simple node file: BrainNet_Visualization_Files\\Early_vs_Advanced_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Early_vs_Advanced_Summary.txt\n",
      "\n",
      "📊 Processing S1_vs_S3...\n",
      "   Found 11 connections for S1_vs_S3\n",
      "   ✅ Successfully mapped 11 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 14 nodes involved in connections\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Early_vs_Intermediate_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created simple node file: BrainNet_Visualization_Files\\Early_vs_Intermediate_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Early_vs_Intermediate_Summary.txt\n",
      "\n",
      "📊 Processing S3_vs_S2...\n",
      "   Found 22 connections for S3_vs_S2\n",
      "   ✅ Successfully mapped 22 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 21 nodes involved in connections\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created simple node file: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_Summary.txt\n",
      "\n",
      "📋 Creating master summary...\n",
      "✅ BRAINNET VIEWER FILES COMPLETE!\n",
      "📁 All files saved to: BrainNet_Visualization_Files\n",
      "📋 Master summary: BrainNet_Visualization_Files\\Master_Summary.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "BrainNet Viewer File Generator for Gold Standard AD Connectivity Connections\n",
    "Creates node and edge files for brain visualization of each comparison\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_brain_visualization_files():\n",
    "    \"\"\"\n",
    "    Creates BrainNet Viewer files for each comparison from gold standard connections\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CREATING BRAINNET VIEWER FILES FOR GOLD STANDARD CONNECTIONS\")\n",
    "    print(\"==========================================================\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 1. SETUP AND DATA LOADING\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Load your gold standard connections\n",
    "    gold_standard_file = 'C:/Users/theya/Downloads/ADNIFinal/FMRIAnalysis/Comprehensive_Publication_Analysis_Corrected/Gold_Standard_Connections_Only_Corrected.csv'\n",
    "    \n",
    "    if not os.path.exists(gold_standard_file):\n",
    "        print(f\"❌ Error: {gold_standard_file} not found!\")\n",
    "        print(\"Please ensure the corrected gold standard CSV is in the current directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ Loading {gold_standard_file}...\")\n",
    "    df = pd.read_csv(gold_standard_file)\n",
    "    \n",
    "    print(f\"✅ Loaded {len(df)} gold standard connections\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 2. DEFINE REFERENCE NODE NAMES (Desikan-Killiany 68)\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Reference node names from BrainNet Viewer (must match exactly)\n",
    "    reference_node_names = [\n",
    "        # Left hemisphere (indices 0-33)\n",
    "        'l.bankssts', 'l.caudalanteriorcingulate', 'l.caudalmiddlefrontal', 'l.cuneus',\n",
    "        'l.entorhinal', 'l.fusiform', 'l.inferiorparietal', 'l.inferiortemporal',\n",
    "        'l.isthmuscingulate', 'l.lateraloccipital', 'l.lateralorbitofrontal', 'l.lingual',\n",
    "        'l.medialorbitofrontal', 'l.middletemporal', 'l.parahippocampal', 'l.paracentral',\n",
    "        'l.parsopercularis', 'l.parsorbitalis', 'l.parstriangularis', 'l.pericalcarine',\n",
    "        'l.postcentral', 'l.posteriorcingulate', 'l.precentral', 'l.precuneus',\n",
    "        'l.rostralanteriorcingulate', 'l.rostralmiddlefrontal', 'l.superiorfrontal', 'l.superiorparietal',\n",
    "        'l.superiortemporal', 'l.supramarginal', 'l.frontalpole', 'l.temporalpole',\n",
    "        'l.transversetemporal', 'l.insula',\n",
    "        # Right hemisphere (indices 34-67)\n",
    "        'r.bankssts', 'r.caudalanteriorcingulate', 'r.caudalmiddlefrontal', 'r.cuneus',\n",
    "        'r.entorhinal', 'r.fusiform', 'r.inferiorparietal', 'r.inferiortemporal',\n",
    "        'r.isthmuscingulate', 'r.lateraloccipital', 'r.lateralorbitofrontal', 'r.lingual',\n",
    "        'r.medialorbitofrontal', 'r.middletemporal', 'r.parahippocampal', 'r.paracentral',\n",
    "        'r.parsopercularis', 'r.parsorbitalis', 'r.parstriangularis', 'r.pericalcarine',\n",
    "        'r.postcentral', 'r.posteriorcingulate', 'r.precentral', 'r.precuneus',\n",
    "        'r.rostralanteriorcingulate', 'r.rostralmiddlefrontal', 'r.superiorfrontal', 'r.superiorparietal',\n",
    "        'r.superiortemporal', 'r.supramarginal', 'r.frontalpole', 'r.temporalpole',\n",
    "        'r.transversetemporal', 'r.insula'\n",
    "    ]\n",
    "    \n",
    "    print(f\"✅ Defined {len(reference_node_names)} reference node names\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 3. CREATE MAPPING FUNCTION\n",
    "    # =============================================================================\n",
    "    \n",
    "    def map_region_name_to_reference(region_name):\n",
    "        \"\"\"\n",
    "        Map your region names (e.g., 'rh-precentral') to reference names (e.g., 'r.precentral')\n",
    "        \"\"\"\n",
    "        if pd.isna(region_name) or region_name == '':\n",
    "            return None\n",
    "            \n",
    "        # Convert 'lh-' to 'l.' and 'rh-' to 'r.'\n",
    "        if region_name.startswith('lh-'):\n",
    "            ref_name = 'l.' + region_name[3:]  # Remove 'lh-' and add 'l.'\n",
    "        elif region_name.startswith('rh-'):\n",
    "            ref_name = 'r.' + region_name[3:]  # Remove 'rh-' and add 'r.'\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Unexpected region name format: {region_name}\")\n",
    "            return None\n",
    "        \n",
    "        # Check if the mapped name exists in reference\n",
    "        if ref_name in reference_node_names:\n",
    "            return ref_name\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Mapped name '{ref_name}' not found in reference nodes\")\n",
    "            return None\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4. PROCESS EACH COMPARISON\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"BrainNet_Visualization_Files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    comparisons = ['S1_vs_S2', 'S1_vs_S3', 'S3_vs_S2']\n",
    "    comparison_labels = {\n",
    "        'S1_vs_S2': 'Early_vs_Advanced',\n",
    "        'S1_vs_S3': 'Early_vs_Intermediate', \n",
    "        'S3_vs_S2': 'Intermediate_vs_Advanced'\n",
    "    }\n",
    "    \n",
    "    for comparison in comparisons:\n",
    "        print(f\"\\n📊 Processing {comparison}...\")\n",
    "        \n",
    "        # Filter data for this comparison\n",
    "        comp_data = df[df['Comparison'] == comparison].copy()\n",
    "        print(f\"   Found {len(comp_data)} connections for {comparison}\")\n",
    "        \n",
    "        if len(comp_data) == 0:\n",
    "            print(f\"   ⚠️ No connections found for {comparison}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 5. CREATE ADJACENCY MATRIX\n",
    "        # =============================================================================\n",
    "        \n",
    "        # Initialize 68x68 matrix with zeros\n",
    "        matrix = np.zeros((68, 68), dtype=int)\n",
    "        \n",
    "        # Track which nodes are involved\n",
    "        involved_nodes = set()\n",
    "        successful_mappings = 0\n",
    "        failed_mappings = 0\n",
    "        \n",
    "        for idx, row in comp_data.iterrows():\n",
    "            # Map region names to reference format\n",
    "            region_a_ref = map_region_name_to_reference(row['RegionA_Name'])\n",
    "            region_b_ref = map_region_name_to_reference(row['RegionB_Name'])\n",
    "            \n",
    "            if region_a_ref is None or region_b_ref is None:\n",
    "                failed_mappings += 1\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            try:\n",
    "                idx_a = reference_node_names.index(region_a_ref)\n",
    "                idx_b = reference_node_names.index(region_b_ref)\n",
    "                \n",
    "                # Set connection strength based on effect size\n",
    "                effect_size = abs(row['Effect_Size'])\n",
    "                \n",
    "                # Map effect size to connection strength (1-3 scale for visualization)\n",
    "                if effect_size >= 1.2:\n",
    "                    strength = 3  # Strong connection\n",
    "                elif effect_size >= 1.0:\n",
    "                    strength = 2  # Medium connection\n",
    "                else:\n",
    "                    strength = 1  # Weak connection\n",
    "                \n",
    "                # Set matrix values (undirected)\n",
    "                matrix[idx_a, idx_b] = strength\n",
    "                matrix[idx_b, idx_a] = strength\n",
    "                \n",
    "                # Track involved nodes\n",
    "                involved_nodes.add(idx_a)\n",
    "                involved_nodes.add(idx_b)\n",
    "                \n",
    "                successful_mappings += 1\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(f\"   ⚠️ Error mapping regions: {region_a_ref}, {region_b_ref}\")\n",
    "                failed_mappings += 1\n",
    "        \n",
    "        print(f\"   ✅ Successfully mapped {successful_mappings} connections\")\n",
    "        print(f\"   ❌ Failed to map {failed_mappings} connections\")\n",
    "        print(f\"   🧠 {len(involved_nodes)} nodes involved in connections\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 6. SAVE EDGE FILE\n",
    "        # =============================================================================\n",
    "        \n",
    "        comp_label = comparison_labels[comparison]\n",
    "        edge_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.edge')\n",
    "        \n",
    "        with open(edge_filename, 'w') as f:\n",
    "            for row in matrix:\n",
    "                f.write(' '.join(map(str, row)) + '\\n')\n",
    "        \n",
    "        print(f\"   💾 Saved edge file: {edge_filename}\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 7. CREATE NODE FILE WITH INVOLVEMENT HIGHLIGHTING\n",
    "        # =============================================================================\n",
    "        \n",
    "        # Read the reference node file\n",
    "        reference_node_file = \"Desikan-Killiany68.node\"\n",
    "        \n",
    "        if os.path.exists(reference_node_file):\n",
    "            print(f\"   📂 Using reference node file: {reference_node_file}\")\n",
    "            \n",
    "            # Load reference node coordinates\n",
    "            try:\n",
    "                # Read node file (assuming format: x y z color size label)\n",
    "                node_data = []\n",
    "                with open(reference_node_file, 'r') as f:\n",
    "                    for line_num, line in enumerate(f):\n",
    "                        line = line.strip()\n",
    "                        if line and not line.startswith('#'):  # Skip comments and empty lines\n",
    "                            parts = line.split()\n",
    "                            if len(parts) >= 6:  # Ensure we have enough columns\n",
    "                                x, y, z = float(parts[0]), float(parts[1]), float(parts[2])\n",
    "                                color = int(parts[3])\n",
    "                                size = int(parts[4])\n",
    "                                label = parts[5] if len(parts) > 5 else f\"node_{line_num}\"\n",
    "                                \n",
    "                                # Highlight nodes involved in connections\n",
    "                                if line_num in involved_nodes:\n",
    "                                    color = 2  # Red color for involved nodes\n",
    "                                    size = 6   # Larger size for involved nodes\n",
    "                                else:\n",
    "                                    color = 1  # Default color\n",
    "                                    size = 3   # Default size\n",
    "                                \n",
    "                                node_data.append([x, y, z, color, size, label])\n",
    "                            else:\n",
    "                                print(f\"   ⚠️ Skipping malformed line {line_num}: {line}\")\n",
    "                \n",
    "                # Save modified node file\n",
    "                node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "                with open(node_filename, 'w') as f:\n",
    "                    for node in node_data:\n",
    "                        f.write(f\"{node[0]:.6f} {node[1]:.6f} {node[2]:.6f} {node[3]} {node[4]} {node[5]}\\n\")\n",
    "                \n",
    "                print(f\"   💾 Saved node file: {node_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error processing reference node file: {e}\")\n",
    "                print(f\"   📝 Creating simple node file instead...\")\n",
    "                \n",
    "                # Create simple node file if reference doesn't work\n",
    "                node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "                with open(node_filename, 'w') as f:\n",
    "                    for i, node_name in enumerate(reference_node_names):\n",
    "                        # Simple coordinates (you may want to use actual brain coordinates)\n",
    "                        x = (i % 10) * 10  # Simple grid layout\n",
    "                        y = (i // 10) * 10\n",
    "                        z = 0\n",
    "                        \n",
    "                        # Highlight involved nodes\n",
    "                        if i in involved_nodes:\n",
    "                            color = 2  # Red\n",
    "                            size = 6\n",
    "                        else:\n",
    "                            color = 1  # Default\n",
    "                            size = 3\n",
    "                        \n",
    "                        f.write(f\"{x} {y} {z} {color} {size} {node_name}\\n\")\n",
    "                \n",
    "                print(f\"   💾 Created simple node file: {node_filename}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"   ⚠️ Reference node file not found, creating simple coordinates...\")\n",
    "            \n",
    "            # Create simple node file\n",
    "            node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "            with open(node_filename, 'w') as f:\n",
    "                for i, node_name in enumerate(reference_node_names):\n",
    "                    # Simple coordinates\n",
    "                    x = (i % 10) * 10\n",
    "                    y = (i // 10) * 10\n",
    "                    z = 0\n",
    "                    \n",
    "                    # Highlight involved nodes\n",
    "                    if i in involved_nodes:\n",
    "                        color = 2  # Red\n",
    "                        size = 6\n",
    "                    else:\n",
    "                        color = 1  # Default\n",
    "                        size = 3\n",
    "                    \n",
    "                    f.write(f\"{x} {y} {z} {color} {size} {node_name}\\n\")\n",
    "            \n",
    "            print(f\"   💾 Created simple node file: {node_filename}\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 8. CREATE SUMMARY FILE\n",
    "        # =============================================================================\n",
    "        \n",
    "        summary_filename = os.path.join(output_dir, f'{comp_label}_Summary.txt')\n",
    "        with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"GOLD STANDARD CONNECTIONS SUMMARY: {comparison}\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Total connections: {len(comp_data)}\\n\")\n",
    "            f.write(f\"Successfully mapped: {successful_mappings}\\n\")\n",
    "            f.write(f\"Failed mappings: {failed_mappings}\\n\")\n",
    "            f.write(f\"Nodes involved: {len(involved_nodes)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"CONNECTION DETAILS:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            for idx, row in comp_data.iterrows():\n",
    "                f.write(f\"{row['RegionA_Name']} <-> {row['RegionB_Name']} \")\n",
    "                f.write(f\"(d={row['Effect_Size']:.3f}, {row['Direction']})\\n\")\n",
    "            \n",
    "            f.write(f\"\\nFiles created:\\n\")\n",
    "            f.write(f\"- {comp_label}_GoldStandard.edge\\n\")\n",
    "            f.write(f\"- {comp_label}_GoldStandard.node\\n\")\n",
    "            f.write(f\"- {comp_label}_Summary.txt\\n\")\n",
    "        \n",
    "        print(f\"   📋 Created summary: {summary_filename}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 9. CREATE MASTER SUMMARY\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n📋 Creating master summary...\")\n",
    "    \n",
    "    master_summary = os.path.join(output_dir, \"Master_Summary.txt\")\n",
    "    with open(master_summary, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"BRAINNET VIEWER FILES FOR GOLD STANDARD AD CONNECTIONS\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"FILES CREATED:\\n\")\n",
    "        f.write(\"-\" * 15 + \"\\n\")\n",
    "        for comparison in comparisons:\n",
    "            comp_label = comparison_labels[comparison]\n",
    "            comp_data = df[df['Comparison'] == comparison]\n",
    "            f.write(f\"\\n{comparison} ({comp_label}):\\n\")\n",
    "            f.write(f\"  - {comp_label}_GoldStandard.edge ({len(comp_data)} connections)\\n\")\n",
    "            f.write(f\"  - {comp_label}_GoldStandard.node (68 nodes)\\n\")\n",
    "            f.write(f\"  - {comp_label}_Summary.txt\\n\")\n",
    "        \n",
    "        f.write(f\"\\nUSAGE INSTRUCTIONS:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(\"1. Open BrainNet Viewer\\n\")\n",
    "        f.write(\"2. Load the .node file for brain regions\\n\")\n",
    "        f.write(\"3. Load the corresponding .edge file for connections\\n\")\n",
    "        f.write(\"4. Involved nodes are highlighted in red with larger size\\n\")\n",
    "        f.write(\"5. Connection strength: 1=weak, 2=medium, 3=strong (based on effect size)\\n\")\n",
    "        f.write(\"\\nEFFECT SIZE MAPPING:\\n\")\n",
    "        f.write(\"- Effect Size ≥ 1.2: Strong connection (3)\\n\")\n",
    "        f.write(\"- Effect Size ≥ 1.0: Medium connection (2)\\n\")\n",
    "        f.write(\"- Effect Size < 1.0: Weak connection (1)\\n\")\n",
    "    \n",
    "    print(f\"✅ BRAINNET VIEWER FILES COMPLETE!\")\n",
    "    print(f\"📁 All files saved to: {output_dir}\")\n",
    "    print(f\"📋 Master summary: {master_summary}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_brain_visualization_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7c08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING BRAINNET VIEWER FILES FOR GOLD STANDARD CONNECTIONS\n",
      "==========================================================\n",
      "✅ Loading C:/Users/theya/Downloads/ADNIFinal/FMRIAnalysis/Comprehensive_Publication_Analysis_Corrected/Gold_Standard_Connections_Only_Corrected.csv...\n",
      "✅ Loaded 53 gold standard connections\n",
      "✅ Defined 68 reference node names\n",
      "\n",
      "📊 Processing S1_vs_S2...\n",
      "   Found 20 connections for S1_vs_S2\n",
      "   ✅ Successfully mapped 20 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 17 nodes involved in connections\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Early_vs_Advanced_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created simple node file: BrainNet_Visualization_Files\\Early_vs_Advanced_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Early_vs_Advanced_Summary.txt\n",
      "\n",
      "📊 Processing S1_vs_S3...\n",
      "   Found 11 connections for S1_vs_S3\n",
      "   ✅ Successfully mapped 11 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 14 nodes involved in connections\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Early_vs_Intermediate_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created simple node file: BrainNet_Visualization_Files\\Early_vs_Intermediate_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Early_vs_Intermediate_Summary.txt\n",
      "\n",
      "📊 Processing S3_vs_S2...\n",
      "   Found 22 connections for S3_vs_S2\n",
      "   ✅ Successfully mapped 22 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 21 nodes involved in connections\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created simple node file: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_Summary.txt\n",
      "\n",
      "📋 Creating master summary...\n",
      "✅ BRAINNET VIEWER FILES COMPLETE!\n",
      "📁 All files saved to: BrainNet_Visualization_Files\n",
      "📋 Master summary: BrainNet_Visualization_Files\\Master_Summary.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "BrainNet Viewer File Generator for Gold Standard AD Connectivity Connections\n",
    "Creates node and edge files for brain visualization of each comparison\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_brain_visualization_files():\n",
    "    \"\"\"\n",
    "    Creates BrainNet Viewer files for each comparison from gold standard connections\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CREATING BRAINNET VIEWER FILES FOR GOLD STANDARD CONNECTIONS\")\n",
    "    print(\"==========================================================\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 1. SETUP AND DATA LOADING\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Load your gold standard connections\n",
    "    gold_standard_file ='C:/Users/theya/Downloads/ADNIFinal/FMRIAnalysis/Comprehensive_Publication_Analysis_Corrected/Gold_Standard_Connections_Only_Corrected.csv'\n",
    "    \n",
    "    if not os.path.exists(gold_standard_file):\n",
    "        print(f\"❌ Error: {gold_standard_file} not found!\")\n",
    "        print(\"Please ensure the corrected gold standard CSV is in the current directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ Loading {gold_standard_file}...\")\n",
    "    df = pd.read_csv(gold_standard_file)\n",
    "    \n",
    "    print(f\"✅ Loaded {len(df)} gold standard connections\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 2. DEFINE REFERENCE NODE NAMES (Desikan-Killiany 68)\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Reference node names from BrainNet Viewer (must match exactly)\n",
    "    reference_node_names = [\n",
    "        # Left hemisphere (indices 0-33)\n",
    "        'l.bankssts', 'l.caudalanteriorcingulate', 'l.caudalmiddlefrontal', 'l.cuneus',\n",
    "        'l.entorhinal', 'l.fusiform', 'l.inferiorparietal', 'l.inferiortemporal',\n",
    "        'l.isthmuscingulate', 'l.lateraloccipital', 'l.lateralorbitofrontal', 'l.lingual',\n",
    "        'l.medialorbitofrontal', 'l.middletemporal', 'l.parahippocampal', 'l.paracentral',\n",
    "        'l.parsopercularis', 'l.parsorbitalis', 'l.parstriangularis', 'l.pericalcarine',\n",
    "        'l.postcentral', 'l.posteriorcingulate', 'l.precentral', 'l.precuneus',\n",
    "        'l.rostralanteriorcingulate', 'l.rostralmiddlefrontal', 'l.superiorfrontal', 'l.superiorparietal',\n",
    "        'l.superiortemporal', 'l.supramarginal', 'l.frontalpole', 'l.temporalpole',\n",
    "        'l.transversetemporal', 'l.insula',\n",
    "        # Right hemisphere (indices 34-67)\n",
    "        'r.bankssts', 'r.caudalanteriorcingulate', 'r.caudalmiddlefrontal', 'r.cuneus',\n",
    "        'r.entorhinal', 'r.fusiform', 'r.inferiorparietal', 'r.inferiortemporal',\n",
    "        'r.isthmuscingulate', 'r.lateraloccipital', 'r.lateralorbitofrontal', 'r.lingual',\n",
    "        'r.medialorbitofrontal', 'r.middletemporal', 'r.parahippocampal', 'r.paracentral',\n",
    "        'r.parsopercularis', 'r.parsorbitalis', 'r.parstriangularis', 'r.pericalcarine',\n",
    "        'r.postcentral', 'r.posteriorcingulate', 'r.precentral', 'r.precuneus',\n",
    "        'r.rostralanteriorcingulate', 'r.rostralmiddlefrontal', 'r.superiorfrontal', 'r.superiorparietal',\n",
    "        'r.superiortemporal', 'r.supramarginal', 'r.frontalpole', 'r.temporalpole',\n",
    "        'r.transversetemporal', 'r.insula'\n",
    "    ]\n",
    "    \n",
    "    print(f\"✅ Defined {len(reference_node_names)} reference node names\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 3. CREATE MAPPING FUNCTION\n",
    "    # =============================================================================\n",
    "    \n",
    "    def map_region_name_to_reference(region_name):\n",
    "        \"\"\"\n",
    "        Map your region names (e.g., 'rh-precentral') to reference names (e.g., 'r.precentral')\n",
    "        \"\"\"\n",
    "        if pd.isna(region_name) or region_name == '':\n",
    "            return None\n",
    "            \n",
    "        # Convert 'lh-' to 'l.' and 'rh-' to 'r.'\n",
    "        if region_name.startswith('lh-'):\n",
    "            ref_name = 'l.' + region_name[3:]  # Remove 'lh-' and add 'l.'\n",
    "        elif region_name.startswith('rh-'):\n",
    "            ref_name = 'r.' + region_name[3:]  # Remove 'rh-' and add 'r.'\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Unexpected region name format: {region_name}\")\n",
    "            return None\n",
    "        \n",
    "        # Check if the mapped name exists in reference\n",
    "        if ref_name in reference_node_names:\n",
    "            return ref_name\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Mapped name '{ref_name}' not found in reference nodes\")\n",
    "            return None\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4. PROCESS EACH COMPARISON\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"BrainNet_Visualization_Files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    comparisons = ['S1_vs_S2', 'S1_vs_S3', 'S3_vs_S2']\n",
    "    comparison_labels = {\n",
    "        'S1_vs_S2': 'Early_vs_Advanced',\n",
    "        'S1_vs_S3': 'Early_vs_Intermediate', \n",
    "        'S3_vs_S2': 'Intermediate_vs_Advanced'\n",
    "    }\n",
    "    \n",
    "    for comparison in comparisons:\n",
    "        print(f\"\\n📊 Processing {comparison}...\")\n",
    "        \n",
    "        # Filter data for this comparison\n",
    "        comp_data = df[df['Comparison'] == comparison].copy()\n",
    "        print(f\"   Found {len(comp_data)} connections for {comparison}\")\n",
    "        \n",
    "        if len(comp_data) == 0:\n",
    "            print(f\"   ⚠️ No connections found for {comparison}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 5. CREATE ADJACENCY MATRIX\n",
    "        # =============================================================================\n",
    "        \n",
    "        # Initialize 68x68 matrix with zeros\n",
    "        matrix = np.zeros((68, 68), dtype=int)\n",
    "        \n",
    "        # Track which nodes are involved\n",
    "        involved_nodes = set()\n",
    "        successful_mappings = 0\n",
    "        failed_mappings = 0\n",
    "        \n",
    "        for idx, row in comp_data.iterrows():\n",
    "            # Map region names to reference format\n",
    "            region_a_ref = map_region_name_to_reference(row['RegionA_Name'])\n",
    "            region_b_ref = map_region_name_to_reference(row['RegionB_Name'])\n",
    "            \n",
    "            if region_a_ref is None or region_b_ref is None:\n",
    "                failed_mappings += 1\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            try:\n",
    "                idx_a = reference_node_names.index(region_a_ref)\n",
    "                idx_b = reference_node_names.index(region_b_ref)\n",
    "                \n",
    "                # Set connection strength and color based on effect size and direction\n",
    "                effect_size = abs(row['Effect_Size'])\n",
    "                direction = row['Direction']\n",
    "                \n",
    "                # Map effect size to connection strength (1-5 scale for better visualization)\n",
    "                if effect_size >= 1.3:\n",
    "                    strength = 5  # Very strong connection\n",
    "                elif effect_size >= 1.1:\n",
    "                    strength = 4  # Strong connection\n",
    "                elif effect_size >= 0.9:\n",
    "                    strength = 3  # Medium connection\n",
    "                elif effect_size >= 0.8:\n",
    "                    strength = 2  # Weak connection\n",
    "                else:\n",
    "                    strength = 1  # Very weak connection\n",
    "                \n",
    "                # Add direction information by using positive/negative values\n",
    "                if direction == 'Decreased':\n",
    "                    strength = -strength  # Negative for decreased connectivity\n",
    "                \n",
    "                # Create network-specific colors for nodes\n",
    "                network_a = row.get('RegionA_RSNName', 'Unknown')\n",
    "                network_b = row.get('RegionB_RSNName', 'Unknown')\n",
    "                \n",
    "                # Define network color mapping\n",
    "                network_colors = {\n",
    "                    'DMN': 3,   # Red - Default Mode Network\n",
    "                    'SM': 4,    # Green - Somatomotor  \n",
    "                    'VA': 5,    # Blue - Ventral Attention\n",
    "                    'VIS': 6,   # Yellow - Visual\n",
    "                    'FP': 7,    # Magenta - Frontoparietal\n",
    "                    'LS': 8,    # Cyan - Limbic System\n",
    "                    'SUB': 9,   # Orange - Subcortical\n",
    "                    'DA': 10    # Purple - Dorsal Attention\n",
    "                }\n",
    "                \n",
    "                # Assign colors based on network\n",
    "                color_a = network_colors.get(network_a, 2)  # Default to red if unknown\n",
    "                color_b = network_colors.get(network_b, 2)\n",
    "                \n",
    "                # Set matrix values (undirected)\n",
    "                matrix[idx_a, idx_b] = strength\n",
    "                matrix[idx_b, idx_a] = strength\n",
    "                \n",
    "                # Track involved nodes with their networks and colors\n",
    "                involved_nodes.add((idx_a, color_a, network_a))\n",
    "                involved_nodes.add((idx_b, color_b, network_b))\n",
    "                \n",
    "                successful_mappings += 1\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(f\"   ⚠️ Error mapping regions: {region_a_ref}, {region_b_ref}\")\n",
    "                failed_mappings += 1\n",
    "        \n",
    "        print(f\"   ✅ Successfully mapped {successful_mappings} connections\")\n",
    "        print(f\"   ❌ Failed to map {failed_mappings} connections\")\n",
    "        print(f\"   🧠 {len(involved_nodes)} nodes involved in connections\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 6. SAVE EDGE FILE\n",
    "        # =============================================================================\n",
    "        \n",
    "        comp_label = comparison_labels[comparison]\n",
    "        edge_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.edge')\n",
    "        \n",
    "        with open(edge_filename, 'w') as f:\n",
    "            for row in matrix:\n",
    "                f.write(' '.join(map(str, row)) + '\\n')\n",
    "        \n",
    "        print(f\"   💾 Saved edge file: {edge_filename}\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 7. CREATE NODE FILE WITH INVOLVEMENT HIGHLIGHTING\n",
    "        # =============================================================================\n",
    "        \n",
    "        # Read the reference node file\n",
    "        reference_node_file = \"Desikan-Killiany68.node\"\n",
    "        \n",
    "        if os.path.exists(reference_node_file):\n",
    "            print(f\"   📂 Using reference node file: {reference_node_file}\")\n",
    "            \n",
    "            # Load reference node coordinates\n",
    "            try:\n",
    "                # Read node file (assuming format: x y z color size label)\n",
    "                node_data = []\n",
    "                with open(reference_node_file, 'r') as f:\n",
    "                    for line_num, line in enumerate(f):\n",
    "                        line = line.strip()\n",
    "                        if line and not line.startswith('#'):  # Skip comments and empty lines\n",
    "                            parts = line.split()\n",
    "                            if len(parts) >= 6:  # Ensure we have enough columns\n",
    "                                x, y, z = float(parts[0]), float(parts[1]), float(parts[2])\n",
    "                                color = int(parts[3])\n",
    "                                size = int(parts[4])\n",
    "                                label = parts[5] if len(parts) > 5 else f\"node_{line_num}\"\n",
    "                                \n",
    "                                # Highlight nodes involved in connections\n",
    "                                if line_num in involved_nodes:\n",
    "                                    color = 2  # Red color for involved nodes\n",
    "                                    size = 6   # Larger size for involved nodes\n",
    "                                else:\n",
    "                                    color = 1  # Default color\n",
    "                                    size = 3   # Default size\n",
    "                                \n",
    "                                node_data.append([x, y, z, color, size, label])\n",
    "                            else:\n",
    "                                print(f\"   ⚠️ Skipping malformed line {line_num}: {line}\")\n",
    "                \n",
    "                # Save modified node file\n",
    "                node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "                with open(node_filename, 'w') as f:\n",
    "                    for node in node_data:\n",
    "                        f.write(f\"{node[0]:.6f} {node[1]:.6f} {node[2]:.6f} {node[3]} {node[4]} {node[5]}\\n\")\n",
    "                \n",
    "                print(f\"   💾 Saved node file: {node_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error processing reference node file: {e}\")\n",
    "                print(f\"   📝 Creating simple node file instead...\")\n",
    "                \n",
    "                # Create simple node file if reference doesn't work\n",
    "                node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "                with open(node_filename, 'w') as f:\n",
    "                    for i, node_name in enumerate(reference_node_names):\n",
    "                        # Simple coordinates (you may want to use actual brain coordinates)\n",
    "                        x = (i % 10) * 10  # Simple grid layout\n",
    "                        y = (i // 10) * 10\n",
    "                        z = 0\n",
    "                        \n",
    "                        # Highlight involved nodes\n",
    "                        if i in involved_nodes:\n",
    "                            color = 2  # Red\n",
    "                            size = 6\n",
    "                        else:\n",
    "                            color = 1  # Default\n",
    "                            size = 3\n",
    "                        \n",
    "                        f.write(f\"{x} {y} {z} {color} {size} {node_name}\\n\")\n",
    "                \n",
    "                print(f\"   💾 Created simple node file: {node_filename}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"   ⚠️ Reference node file not found, creating simple coordinates...\")\n",
    "            \n",
    "            # Create simple node file\n",
    "            node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "            with open(node_filename, 'w') as f:\n",
    "                for i, node_name in enumerate(reference_node_names):\n",
    "                    # Simple coordinates\n",
    "                    x = (i % 10) * 10\n",
    "                    y = (i // 10) * 10\n",
    "                    z = 0\n",
    "                    \n",
    "                    # Highlight involved nodes\n",
    "                    if i in involved_nodes:\n",
    "                        color = 2  # Red\n",
    "                        size = 6\n",
    "                    else:\n",
    "                        color = 1  # Default\n",
    "                        size = 3\n",
    "                    \n",
    "                    f.write(f\"{x} {y} {z} {color} {size} {node_name}\\n\")\n",
    "            \n",
    "            print(f\"   💾 Created simple node file: {node_filename}\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 8. CREATE SUMMARY FILE\n",
    "        # =============================================================================\n",
    "        \n",
    "        summary_filename = os.path.join(output_dir, f'{comp_label}_Summary.txt')\n",
    "        with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"GOLD STANDARD CONNECTIONS SUMMARY: {comparison}\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Total connections: {len(comp_data)}\\n\")\n",
    "            f.write(f\"Successfully mapped: {successful_mappings}\\n\")\n",
    "            f.write(f\"Failed mappings: {failed_mappings}\\n\")\n",
    "            f.write(f\"Nodes involved: {len(involved_nodes)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"CONNECTION DETAILS:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            for idx, row in comp_data.iterrows():\n",
    "                f.write(f\"{row['RegionA_Name']} <-> {row['RegionB_Name']} \")\n",
    "                f.write(f\"(d={row['Effect_Size']:.3f}, {row['Direction']})\\n\")\n",
    "            \n",
    "            f.write(f\"\\nFiles created:\\n\")\n",
    "            f.write(f\"- {comp_label}_GoldStandard.edge\\n\")\n",
    "            f.write(f\"- {comp_label}_GoldStandard.node\\n\")\n",
    "            f.write(f\"- {comp_label}_Summary.txt\\n\")\n",
    "        \n",
    "        print(f\"   📋 Created summary: {summary_filename}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 9. CREATE MASTER SUMMARY\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n📋 Creating master summary...\")\n",
    "    \n",
    "    master_summary = os.path.join(output_dir, \"Master_Summary.txt\")\n",
    "    with open(master_summary, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"BRAINNET VIEWER FILES FOR GOLD STANDARD AD CONNECTIONS\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"FILES CREATED:\\n\")\n",
    "        f.write(\"-\" * 15 + \"\\n\")\n",
    "        for comparison in comparisons:\n",
    "            comp_label = comparison_labels[comparison]\n",
    "            comp_data = df[df['Comparison'] == comparison]\n",
    "            f.write(f\"\\n{comparison} ({comp_label}):\\n\")\n",
    "            f.write(f\"  - {comp_label}_GoldStandard.edge ({len(comp_data)} connections)\\n\")\n",
    "            f.write(f\"  - {comp_label}_GoldStandard.node (68 nodes)\\n\")\n",
    "            f.write(f\"  - {comp_label}_Summary.txt\\n\")\n",
    "        \n",
    "        f.write(f\"\\nUSAGE INSTRUCTIONS:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(\"1. Open BrainNet Viewer\\n\")\n",
    "        f.write(\"2. Load the .node file for brain regions\\n\")\n",
    "        f.write(\"3. Load the corresponding .edge file for connections\\n\")\n",
    "        f.write(\"4. Involved nodes are highlighted in red with larger size\\n\")\n",
    "        f.write(\"5. Connection strength: 1=weak, 2=medium, 3=strong (based on effect size)\\n\")\n",
    "        f.write(\"\\nEFFECT SIZE MAPPING:\\n\")\n",
    "        f.write(\"- Effect Size ≥ 1.2: Strong connection (3)\\n\")\n",
    "        f.write(\"- Effect Size ≥ 1.0: Medium connection (2)\\n\")\n",
    "        f.write(\"- Effect Size < 1.0: Weak connection (1)\\n\")\n",
    "    \n",
    "    print(f\"✅ BRAINNET VIEWER FILES COMPLETE!\")\n",
    "    print(f\"📁 All files saved to: {output_dir}\")\n",
    "    print(f\"📋 Master summary: {master_summary}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_brain_visualization_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b41143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING BRAINNET VIEWER FILES FOR GOLD STANDARD CONNECTIONS\n",
      "==========================================================\n",
      "✅ Loading C:/Users/theya/Downloads/ADNIFinal/FMRIAnalysis/Comprehensive_Publication_Analysis_Corrected/Gold_Standard_Connections_Only_Corrected.csv...\n",
      "✅ Loaded 53 gold standard connections\n",
      "✅ Defined 68 reference node names\n",
      "\n",
      "📊 Processing S1_vs_S2...\n",
      "   Found 20 connections for S1_vs_S2\n",
      "   ✅ Successfully mapped 20 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 17 nodes involved in connections\n",
      "   🎨 Network distribution: {'VA': 3, 'DMN': 7, 'LS': 2, 'SM': 2, 'FP': 2, 'SUB': 1}\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Early_vs_Advanced_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created network-colored node file: BrainNet_Visualization_Files\\Early_vs_Advanced_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Early_vs_Advanced_Summary.txt\n",
      "\n",
      "📊 Processing S1_vs_S3...\n",
      "   Found 11 connections for S1_vs_S3\n",
      "   ✅ Successfully mapped 11 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 14 nodes involved in connections\n",
      "   🎨 Network distribution: {'DMN': 9, 'SM': 1, 'LS': 2, 'FP': 2}\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Early_vs_Intermediate_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created network-colored node file: BrainNet_Visualization_Files\\Early_vs_Intermediate_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Early_vs_Intermediate_Summary.txt\n",
      "\n",
      "📊 Processing S3_vs_S2...\n",
      "   Found 22 connections for S3_vs_S2\n",
      "   ✅ Successfully mapped 22 connections\n",
      "   ❌ Failed to map 0 connections\n",
      "   🧠 21 nodes involved in connections\n",
      "   🎨 Network distribution: {'SM': 7, 'VIS': 4, 'DMN': 3, 'VA': 2, 'FP': 2, 'LS': 2, 'SUB': 1}\n",
      "   💾 Saved edge file: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_GoldStandard.edge\n",
      "   📂 Using reference node file: Desikan-Killiany68.node\n",
      "   ❌ Error processing reference node file: invalid literal for int() with base 10: '1.000000'\n",
      "   📝 Creating simple node file instead...\n",
      "   💾 Created network-colored node file: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_GoldStandard.node\n",
      "   📋 Created summary: BrainNet_Visualization_Files\\Intermediate_vs_Advanced_Summary.txt\n",
      "\n",
      "📋 Creating master summary...\n",
      "✅ BRAINNET VIEWER FILES COMPLETE!\n",
      "📁 All files saved to: BrainNet_Visualization_Files\n",
      "📋 Master summary: BrainNet_Visualization_Files\\Master_Summary.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "BrainNet Viewer File Generator for Gold Standard AD Connectivity Connections\n",
    "Creates node and edge files for brain visualization of each comparison\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def create_brain_visualization_files():\n",
    "    \"\"\"\n",
    "    Creates BrainNet Viewer files for each comparison from gold standard connections\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CREATING BRAINNET VIEWER FILES FOR GOLD STANDARD CONNECTIONS\")\n",
    "    print(\"==========================================================\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 1. SETUP AND DATA LOADING\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Load your gold standard connections\n",
    "    gold_standard_file = 'C:/Users/theya/Downloads/ADNIFinal/FMRIAnalysis/Comprehensive_Publication_Analysis_Corrected/Gold_Standard_Connections_Only_Corrected.csv'\n",
    "    \n",
    "    if not os.path.exists(gold_standard_file):\n",
    "        print(f\"❌ Error: {gold_standard_file} not found!\")\n",
    "        print(\"Please ensure the corrected gold standard CSV is in the current directory.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"✅ Loading {gold_standard_file}...\")\n",
    "    df = pd.read_csv(gold_standard_file)\n",
    "    \n",
    "    print(f\"✅ Loaded {len(df)} gold standard connections\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 2. DEFINE REFERENCE NODE NAMES (Desikan-Killiany 68)\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Reference node names from BrainNet Viewer (must match exactly)\n",
    "    reference_node_names = [\n",
    "        # Left hemisphere (indices 0-33)\n",
    "        'l.bankssts', 'l.caudalanteriorcingulate', 'l.caudalmiddlefrontal', 'l.cuneus',\n",
    "        'l.entorhinal', 'l.fusiform', 'l.inferiorparietal', 'l.inferiortemporal',\n",
    "        'l.isthmuscingulate', 'l.lateraloccipital', 'l.lateralorbitofrontal', 'l.lingual',\n",
    "        'l.medialorbitofrontal', 'l.middletemporal', 'l.parahippocampal', 'l.paracentral',\n",
    "        'l.parsopercularis', 'l.parsorbitalis', 'l.parstriangularis', 'l.pericalcarine',\n",
    "        'l.postcentral', 'l.posteriorcingulate', 'l.precentral', 'l.precuneus',\n",
    "        'l.rostralanteriorcingulate', 'l.rostralmiddlefrontal', 'l.superiorfrontal', 'l.superiorparietal',\n",
    "        'l.superiortemporal', 'l.supramarginal', 'l.frontalpole', 'l.temporalpole',\n",
    "        'l.transversetemporal', 'l.insula',\n",
    "        # Right hemisphere (indices 34-67)\n",
    "        'r.bankssts', 'r.caudalanteriorcingulate', 'r.caudalmiddlefrontal', 'r.cuneus',\n",
    "        'r.entorhinal', 'r.fusiform', 'r.inferiorparietal', 'r.inferiortemporal',\n",
    "        'r.isthmuscingulate', 'r.lateraloccipital', 'r.lateralorbitofrontal', 'r.lingual',\n",
    "        'r.medialorbitofrontal', 'r.middletemporal', 'r.parahippocampal', 'r.paracentral',\n",
    "        'r.parsopercularis', 'r.parsorbitalis', 'r.parstriangularis', 'r.pericalcarine',\n",
    "        'r.postcentral', 'r.posteriorcingulate', 'r.precentral', 'r.precuneus',\n",
    "        'r.rostralanteriorcingulate', 'r.rostralmiddlefrontal', 'r.superiorfrontal', 'r.superiorparietal',\n",
    "        'r.superiortemporal', 'r.supramarginal', 'r.frontalpole', 'r.temporalpole',\n",
    "        'r.transversetemporal', 'r.insula'\n",
    "    ]\n",
    "    \n",
    "    print(f\"✅ Defined {len(reference_node_names)} reference node names\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 3. CREATE MAPPING FUNCTION\n",
    "    # =============================================================================\n",
    "    \n",
    "    def map_region_name_to_reference(region_name):\n",
    "        \"\"\"\n",
    "        Map your region names (e.g., 'rh-precentral') to reference names (e.g., 'r.precentral')\n",
    "        \"\"\"\n",
    "        if pd.isna(region_name) or region_name == '':\n",
    "            return None\n",
    "            \n",
    "        # Convert 'lh-' to 'l.' and 'rh-' to 'r.'\n",
    "        if region_name.startswith('lh-'):\n",
    "            ref_name = 'l.' + region_name[3:]  # Remove 'lh-' and add 'l.'\n",
    "        elif region_name.startswith('rh-'):\n",
    "            ref_name = 'r.' + region_name[3:]  # Remove 'rh-' and add 'r.'\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Unexpected region name format: {region_name}\")\n",
    "            return None\n",
    "        \n",
    "        # Check if the mapped name exists in reference\n",
    "        if ref_name in reference_node_names:\n",
    "            return ref_name\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: Mapped name '{ref_name}' not found in reference nodes\")\n",
    "            return None\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 4. PROCESS EACH COMPARISON\n",
    "    # =============================================================================\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"BrainNet_Visualization_Files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    comparisons = ['S1_vs_S2', 'S1_vs_S3', 'S3_vs_S2']\n",
    "    comparison_labels = {\n",
    "        'S1_vs_S2': 'Early_vs_Advanced',\n",
    "        'S1_vs_S3': 'Early_vs_Intermediate', \n",
    "        'S3_vs_S2': 'Intermediate_vs_Advanced'\n",
    "    }\n",
    "    \n",
    "    for comparison in comparisons:\n",
    "        print(f\"\\n📊 Processing {comparison}...\")\n",
    "        \n",
    "        # Filter data for this comparison\n",
    "        comp_data = df[df['Comparison'] == comparison].copy()\n",
    "        print(f\"   Found {len(comp_data)} connections for {comparison}\")\n",
    "        \n",
    "        if len(comp_data) == 0:\n",
    "            print(f\"   ⚠️ No connections found for {comparison}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 5. CREATE ADJACENCY MATRIX\n",
    "        # =============================================================================\n",
    "        \n",
    "        # Initialize 68x68 matrix with zeros\n",
    "        matrix = np.zeros((68, 68), dtype=int)\n",
    "        \n",
    "        # Track which nodes are involved\n",
    "        involved_nodes = set()\n",
    "        successful_mappings = 0\n",
    "        failed_mappings = 0\n",
    "        \n",
    "        for idx, row in comp_data.iterrows():\n",
    "            # Map region names to reference format\n",
    "            region_a_ref = map_region_name_to_reference(row['RegionA_Name'])\n",
    "            region_b_ref = map_region_name_to_reference(row['RegionB_Name'])\n",
    "            \n",
    "            if region_a_ref is None or region_b_ref is None:\n",
    "                failed_mappings += 1\n",
    "                continue\n",
    "            \n",
    "            # Get matrix indices\n",
    "            try:\n",
    "                idx_a = reference_node_names.index(region_a_ref)\n",
    "                idx_b = reference_node_names.index(region_b_ref)\n",
    "                \n",
    "                # Set connection strength and color based on effect size and direction\n",
    "                effect_size = abs(row['Effect_Size'])\n",
    "                direction = row['Direction']\n",
    "                \n",
    "                # Map effect size to connection strength (1-5 scale for better visualization)\n",
    "                if effect_size >= 1.3:\n",
    "                    strength = 5  # Very strong connection\n",
    "                elif effect_size >= 1.1:\n",
    "                    strength = 4  # Strong connection\n",
    "                elif effect_size >= 0.9:\n",
    "                    strength = 3  # Medium connection\n",
    "                elif effect_size >= 0.8:\n",
    "                    strength = 2  # Weak connection\n",
    "                else:\n",
    "                    strength = 1  # Very weak connection\n",
    "                \n",
    "                # Add direction information by using positive/negative values\n",
    "                if direction == 'Decreased':\n",
    "                    strength = -strength  # Negative for decreased connectivity\n",
    "                \n",
    "                # Create network-specific colors for nodes\n",
    "                network_a = row.get('RegionA_RSNName', 'Unknown')\n",
    "                network_b = row.get('RegionB_RSNName', 'Unknown')\n",
    "                \n",
    "                # Define network color mapping\n",
    "                network_colors = {\n",
    "                    'DMN': 3,   # Red - Default Mode Network\n",
    "                    'SM': 4,    # Green - Somatomotor  \n",
    "                    'VA': 5,    # Blue - Ventral Attention\n",
    "                    'VIS': 6,   # Yellow - Visual\n",
    "                    'FP': 7,    # Magenta - Frontoparietal\n",
    "                    'LS': 8,    # Cyan - Limbic System\n",
    "                    'SUB': 9,   # Orange - Subcortical\n",
    "                    'DA': 10    # Purple - Dorsal Attention\n",
    "                }\n",
    "                \n",
    "                # Assign colors based on network\n",
    "                color_a = network_colors.get(network_a, 2)  # Default to red if unknown\n",
    "                color_b = network_colors.get(network_b, 2)\n",
    "                \n",
    "                # Set matrix values (undirected)\n",
    "                matrix[idx_a, idx_b] = strength\n",
    "                matrix[idx_b, idx_a] = strength\n",
    "                \n",
    "                # Track involved nodes with their networks and colors\n",
    "                involved_nodes.add((idx_a, color_a, network_a))\n",
    "                involved_nodes.add((idx_b, color_b, network_b))\n",
    "                \n",
    "                successful_mappings += 1\n",
    "                \n",
    "            except ValueError as e:\n",
    "                print(f\"   ⚠️ Error mapping regions: {region_a_ref}, {region_b_ref}\")\n",
    "                failed_mappings += 1\n",
    "        \n",
    "        print(f\"   ✅ Successfully mapped {successful_mappings} connections\")\n",
    "        print(f\"   ❌ Failed to map {failed_mappings} connections\")\n",
    "        print(f\"   🧠 {len(involved_nodes)} nodes involved in connections\")\n",
    "        \n",
    "        # Count nodes by network\n",
    "        network_counts = {}\n",
    "        for node_idx, color, network in involved_nodes:\n",
    "            network_counts[network] = network_counts.get(network, 0) + 1\n",
    "        \n",
    "        print(f\"   🎨 Network distribution: {dict(network_counts)}\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 6. SAVE EDGE FILE\n",
    "        # =============================================================================\n",
    "        \n",
    "        comp_label = comparison_labels[comparison]\n",
    "        edge_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.edge')\n",
    "        \n",
    "        with open(edge_filename, 'w') as f:\n",
    "            for row in matrix:\n",
    "                f.write(' '.join(map(str, row)) + '\\n')\n",
    "        \n",
    "        print(f\"   💾 Saved edge file: {edge_filename}\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 7. CREATE NODE FILE WITH INVOLVEMENT HIGHLIGHTING\n",
    "        # =============================================================================\n",
    "        \n",
    "        # Read the reference node file\n",
    "        reference_node_file = \"Desikan-Killiany68.node\"\n",
    "        \n",
    "        if os.path.exists(reference_node_file):\n",
    "            print(f\"   📂 Using reference node file: {reference_node_file}\")\n",
    "            \n",
    "            # Load reference node coordinates\n",
    "            try:\n",
    "                # Read node file (assuming format: x y z color size label)\n",
    "                node_data = []\n",
    "                with open(reference_node_file, 'r') as f:\n",
    "                    for line_num, line in enumerate(f):\n",
    "                        line = line.strip()\n",
    "                        if line and not line.startswith('#'):  # Skip comments and empty lines\n",
    "                            parts = line.split()\n",
    "                            if len(parts) >= 6:  # Ensure we have enough columns\n",
    "                                x, y, z = float(parts[0]), float(parts[1]), float(parts[2])\n",
    "                                color = int(parts[3])\n",
    "                                size = int(parts[4])\n",
    "                                label = parts[5] if len(parts) > 5 else f\"node_{line_num}\"\n",
    "                                \n",
    "                                # Create network-based coloring for involved nodes\n",
    "                                network_colors = {\n",
    "                                    'DMN': 3, 'SM': 4, 'VA': 5, 'VIS': 6, \n",
    "                                    'FP': 7, 'LS': 8, 'SUB': 9, 'DA': 10\n",
    "                                }\n",
    "                                \n",
    "                                # Check if this node is involved in connections\n",
    "                                node_color = 1   # Default gray\n",
    "                                node_size = 3    # Default size\n",
    "                                \n",
    "                                for node_idx, color, network in involved_nodes:\n",
    "                                    if node_idx == line_num:\n",
    "                                        node_color = color\n",
    "                                        node_size = 8  # Larger for involved nodes\n",
    "                                        break\n",
    "                                \n",
    "                                node_data.append([x, y, z, node_color, node_size, label])\n",
    "                            else:\n",
    "                                print(f\"   ⚠️ Skipping malformed line {line_num}: {line}\")\n",
    "                \n",
    "                # Save modified node file\n",
    "                node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "                with open(node_filename, 'w') as f:\n",
    "                    for node in node_data:\n",
    "                        f.write(f\"{node[0]:.6f} {node[1]:.6f} {node[2]:.6f} {node[3]} {node[4]} {node[5]}\\n\")\n",
    "                \n",
    "                print(f\"   💾 Saved node file: {node_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ Error processing reference node file: {e}\")\n",
    "                print(f\"   📝 Creating simple node file instead...\")\n",
    "                \n",
    "                # Create comprehensive node file with network-based coloring\n",
    "                node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "                with open(node_filename, 'w', encoding='utf-8') as f:\n",
    "                    f.write(\"# Node file for BrainNet Viewer\\n\")\n",
    "                    f.write(\"# Format: X Y Z Color Size Label\\n\")\n",
    "                    f.write(\"# Colors: 1=Gray(default), 3=Red(DMN), 4=Green(SM), 5=Blue(VA), 6=Yellow(VIS), 7=Magenta(FP), 8=Cyan(LS), 9=Orange(SUB), 10=Purple(DA)\\n\")\n",
    "                    \n",
    "                    for i, node_name in enumerate(reference_node_names):\n",
    "                        # Simple coordinates (you may want to use actual brain coordinates)\n",
    "                        x = (i % 10) * 10  # Simple grid layout\n",
    "                        y = (i // 10) * 10\n",
    "                        z = 0\n",
    "                        \n",
    "                        # Find if this node is involved and get its color\n",
    "                        node_color = 1  # Default gray\n",
    "                        node_size = 3   # Default size\n",
    "                        \n",
    "                        for node_idx, color, network in involved_nodes:\n",
    "                            if node_idx == i:\n",
    "                                node_color = color\n",
    "                                node_size = 8  # Larger for involved nodes\n",
    "                                break\n",
    "                        \n",
    "                        f.write(f\"{x} {y} {z} {node_color} {node_size} {node_name}\\n\")\n",
    "                \n",
    "                print(f\"   💾 Created network-colored node file: {node_filename}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"   ⚠️ Reference node file not found, creating simple coordinates...\")\n",
    "            \n",
    "            # Create network-colored node file\n",
    "            node_filename = os.path.join(output_dir, f'{comp_label}_GoldStandard.node')\n",
    "            with open(node_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(\"# Node file with network-based colors\\n\")\n",
    "                f.write(\"# Colors: 1=Gray(default), 3=Red(DMN), 4=Green(SM), 5=Blue(VA), 6=Yellow(VIS), 7=Magenta(FP), 8=Cyan(LS), 9=Orange(SUB), 10=Purple(DA)\\n\")\n",
    "                \n",
    "                for i, node_name in enumerate(reference_node_names):\n",
    "                    # Simple coordinates\n",
    "                    x = (i % 10) * 10\n",
    "                    y = (i // 10) * 10\n",
    "                    z = 0\n",
    "                    \n",
    "                    # Network-based coloring for involved nodes\n",
    "                    node_color = 1  # Default gray\n",
    "                    node_size = 3   # Default size\n",
    "                    \n",
    "                    for node_idx, color, network in involved_nodes:\n",
    "                        if node_idx == i:\n",
    "                            node_color = color\n",
    "                            node_size = 8  # Larger for involved nodes\n",
    "                            break\n",
    "                    \n",
    "                    f.write(f\"{x} {y} {z} {node_color} {node_size} {node_name}\\n\")\n",
    "            \n",
    "            print(f\"   💾 Created network-colored node file: {node_filename}\")\n",
    "        \n",
    "        # =============================================================================\n",
    "        # 8. CREATE SUMMARY FILE\n",
    "        # =============================================================================\n",
    "        \n",
    "        summary_filename = os.path.join(output_dir, f'{comp_label}_Summary.txt')\n",
    "        with open(summary_filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"GOLD STANDARD CONNECTIONS SUMMARY: {comparison}\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Total connections: {len(comp_data)}\\n\")\n",
    "            f.write(f\"Successfully mapped: {successful_mappings}\\n\")\n",
    "            f.write(f\"Failed mappings: {failed_mappings}\\n\")\n",
    "            f.write(f\"Nodes involved: {len(involved_nodes)}\\n\\n\")\n",
    "            \n",
    "            f.write(\"CONNECTION DETAILS:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            for idx, row in comp_data.iterrows():\n",
    "                f.write(f\"{row['RegionA_Name']} <-> {row['RegionB_Name']} \")\n",
    "                f.write(f\"(d={row['Effect_Size']:.3f}, {row['Direction']})\\n\")\n",
    "            \n",
    "            f.write(f\"\\nFiles created:\\n\")\n",
    "            f.write(f\"- {comp_label}_GoldStandard.edge\\n\")\n",
    "            f.write(f\"- {comp_label}_GoldStandard.node\\n\")\n",
    "            f.write(f\"- {comp_label}_Summary.txt\\n\")\n",
    "        \n",
    "        print(f\"   📋 Created summary: {summary_filename}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 9. CREATE MASTER SUMMARY\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n📋 Creating master summary...\")\n",
    "    \n",
    "    master_summary = os.path.join(output_dir, \"Master_Summary.txt\")\n",
    "    with open(master_summary, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"BRAINNET VIEWER FILES FOR GOLD STANDARD AD CONNECTIONS\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"FILES CREATED:\\n\")\n",
    "        f.write(\"-\" * 15 + \"\\n\")\n",
    "        for comparison in comparisons:\n",
    "            comp_label = comparison_labels[comparison]\n",
    "            comp_data = df[df['Comparison'] == comparison]\n",
    "            f.write(f\"\\n{comparison} ({comp_label}):\\n\")\n",
    "            f.write(f\"  - {comp_label}_GoldStandard.edge ({len(comp_data)} connections)\\n\")\n",
    "            f.write(f\"  - {comp_label}_GoldStandard.node (68 nodes)\\n\")\n",
    "            f.write(f\"  - {comp_label}_Summary.txt\\n\")\n",
    "        \n",
    "        f.write(f\"\\nUSAGE INSTRUCTIONS:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(\"1. Open BrainNet Viewer\\n\")\n",
    "        f.write(\"2. Load the .node file for brain regions\\n\")\n",
    "        f.write(\"3. Load the corresponding .edge file for connections\\n\")\n",
    "        f.write(\"4. Nodes are colored by brain network:\\n\")\n",
    "        f.write(\"   - Red: Default Mode Network (DMN)\\n\")\n",
    "        f.write(\"   - Green: Somatomotor (SM)\\n\") \n",
    "        f.write(\"   - Blue: Ventral Attention (VA)\\n\")\n",
    "        f.write(\"   - Yellow: Visual (VIS)\\n\")\n",
    "        f.write(\"   - Magenta: Frontoparietal (FP)\\n\")\n",
    "        f.write(\"   - Cyan: Limbic System (LS)\\n\")\n",
    "        f.write(\"   - Orange: Subcortical (SUB)\\n\")\n",
    "        f.write(\"   - Purple: Dorsal Attention (DA)\\n\")\n",
    "        f.write(\"   - Gray: Uninvolved nodes\\n\")\n",
    "        f.write(\"5. Connection strength: Positive=Increased, Negative=Decreased\\n\")\n",
    "        f.write(\"6. Effect size mapping:\\n\")\n",
    "        f.write(\"   - ±5: Very strong (|d| ≥ 1.3)\\n\")\n",
    "        f.write(\"   - ±4: Strong (|d| ≥ 1.1)\\n\")\n",
    "        f.write(\"   - ±3: Medium (|d| ≥ 0.9)\\n\")\n",
    "        f.write(\"   - ±2: Weak (|d| ≥ 0.8)\\n\")\n",
    "        f.write(\"   - ±1: Very weak (|d| < 0.8)\\n\")\n",
    "    \n",
    "    print(f\"✅ BRAINNET VIEWER FILES COMPLETE!\")\n",
    "    print(f\"📁 All files saved to: {output_dir}\")\n",
    "    print(f\"📋 Master summary: {master_summary}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_brain_visualization_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6b4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
